{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ly2asouGDK5u",
        "H6xMi5nGvmHY",
        "t-QNcAm9vVWy",
        "_ZaI2QH25yh2",
        "uT92eV35mvn9",
        "EBiVexNOnb4V",
        "2ypSV0zmuODz",
        "-GFIHcYN9rtg"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ly2asouGDK5u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Starter pack, imports"
      ]
    },
    {
      "metadata": {
        "id": "jcTauyfjDSsP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Libraries"
      ]
    },
    {
      "metadata": {
        "id": "1NPtWQOSliV9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.autograd as autograd\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n",
        "\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0SYMg2ADUg4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Files import"
      ]
    },
    {
      "metadata": {
        "id": "QjwXzilPECwM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Please ** import the corresponding files into the google collab by selecting \"files\" -> \"import\"**. The execution of further cells won't ork otherwise. All these files can be found on the git repository in the /data folder."
      ]
    },
    {
      "metadata": {
        "id": "DPCpxtywICom",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "List of files to import :\n",
        "\n",
        "\n",
        "*  \"corpus_tweets.txt\"\n",
        "*  \"corpus_tweets_subtask_b.txt\"\n",
        "*  \"corpus_tweets_subtask_c.txt\"\n",
        "*  \"labels_1.txt\"\n",
        "*  \"labels_subtask_b.txt\"\n",
        "*  \"labels_subtask_c.txt\"\n",
        "*  \"emb_dic.txt\"\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "e_D6ZqIWG9RD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tokenized cleaned corpus for each task"
      ]
    },
    {
      "metadata": {
        "id": "-ZOArGN4Guwu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  <-------------- Tokenized corpus, specific to each task -------------> #\n",
        "\n",
        "# Get the cleaned tokenized corpus back for a preprocessed .txt file\n",
        "\n",
        "# Whole corpus : for task A\n",
        "with open(\"corpus_tweets.txt\", \"r\") as file:\n",
        "    tmp = file.read().splitlines()\n",
        "\n",
        "tokenized_corpus = [[token for token in sentence.split(' ')][:-1] for sentence in tmp]\n",
        "\n",
        "# Task B\n",
        "with open(\"corpus_tweets_subtask_b.txt\", \"r\") as file:\n",
        "    tmp_b = file.read().splitlines()\n",
        "\n",
        "tokenized_corpus_b = [[token for token in sentence.split(' ')][:-1] for sentence in tmp_b]\n",
        "\n",
        "# Task C\n",
        "with open(\"corpus_tweets_subtask_c.txt\", \"r\") as file:\n",
        "    tmp_c = file.read().splitlines()\n",
        "\n",
        "tokenized_corpus_c = [[token for token in sentence.split(' ')][:-1] for sentence in tmp_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6BSOVucSHAcb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Labels transformed to integers for each task"
      ]
    },
    {
      "metadata": {
        "id": "XaCS-bhsG1JN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#  <--------- Labels transformed to int, specific to each task --------> #\n",
        "\n",
        "# Task A : 0 = \"NOT\" , 1 = \"OFF\"\n",
        "with open(\"labels_1.txt\", \"r\") as file:\n",
        "    label1 = file.read().splitlines()\n",
        "label1 = [float(i) for i in label1]\n",
        "\n",
        "# Task B : 0 = \"UNT\" , 1 = \"TIN\"\n",
        "with open(\"labels_subtask_b.txt\", \"r\") as file:\n",
        "    label_b = file.read().splitlines()\n",
        "label_b = [float(i) for i in label_b]\n",
        "\n",
        "# Task C : 0 = \"OTH\" , 1 = \"IND\", 2 = \"GRP\"\n",
        "with open(\"labels_subtask_c.txt\", \"r\") as file:\n",
        "    label_c = file.read().splitlines()\n",
        "label_c = [float(i) for i in label_c]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5SaSYSBgLNbd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Embedding dictionnary"
      ]
    },
    {
      "metadata": {
        "id": "U1iwC3tmLyDf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This function creates a dictionnary of all embeddings present in a .txt file\n",
        "def extract_dic(path):\n",
        "    dic = {}\n",
        "    glove = open(embedding_path)\n",
        "    for line in glove:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        try:\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            if len(vector) != 100:\n",
        "                print(word, len(vector))\n",
        "            dic[word] = vector\n",
        "        except:\n",
        "            print(\"Parsing problem on word \", word, \" discarding it\")\n",
        "    glove.close()\n",
        "    return dic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YwEgclSbLQdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f468595-2188-4ec0-ef65-d97bc459c292"
      },
      "cell_type": "code",
      "source": [
        "embedding_path = 'emb_dic.txt'\n",
        "\n",
        "emb_dict = extract_dic(embedding_path)\n",
        "print(len(emb_dict['should']))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "olGnjl107LJl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Device selection : run on GPU"
      ]
    },
    {
      "metadata": {
        "id": "-dnu9vjq7NPX",
        "colab_type": "code",
        "outputId": "69f08b23-25cf-401a-f60d-3a35a0f87dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "GPU = True\n",
        "device_idx = 0\n",
        "if GPU:\n",
        "    device = torch.device(\"cuda:\" + str(device_idx) if torch.cuda.is_available() else \"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)\n",
        "cpu = torch.device(\"cpu\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cs2G9W3D7OsZ",
        "colab_type": "code",
        "outputId": "4da8ce80-3fff-439e-f7f3-fe72fbef3414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# We set a random seed to ensure that your results are reproducible.\n",
        "if torch.cuda.is_available():\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f476bb6cfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "H6xMi5nGvmHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Word embedding from GloVe"
      ]
    },
    {
      "metadata": {
        "id": "n0ABHOBgTgoL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We define a function that builds the input for our neural networks from the embedding dictionnary and our corpus of tweets: it operates the translation of each string in each tweets to its embedding representation."
      ]
    },
    {
      "metadata": {
        "id": "mz3-EIT-VFMF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are two versions of this corpus embedding. In the first one, the embedding of a sentence is the mean of the embedding of its tokens. Thus, the shape of each sentence embedding is [1;100], the same as the word embedding"
      ]
    },
    {
      "metadata": {
        "id": "VY1C19a803Y8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def embed_corpus(emb_dict, corpus):\n",
        "    # Prepare container for tweet embeddings\n",
        "    inputs_ = torch.zeros((len(corpus), 100))\n",
        "\n",
        "    # Counter for debugging purposes\n",
        "    count_not_found = 0.\n",
        "    total_count = 0.\n",
        "\n",
        "    # We loop over all the tweets in the corpus\n",
        "    for idx, sentence in enumerate(corpus):\n",
        "        sentence_length = len(sentence)\n",
        "        mean_embedding = torch.zeros(100)\n",
        "        for word in sentence:\n",
        "            total_count += 1\n",
        "            if word in emb_dict.keys():\n",
        "                mean_embedding += torch.Tensor(emb_dict[word])\n",
        "            else:\n",
        "                count_not_found += 1\n",
        "\n",
        "        # We average the word embedding over the sentence\n",
        "        mean_embedding /= sentence_length\n",
        "\n",
        "        # We add the embedded sentence to the inputs tensor\n",
        "        inputs_[idx] = mean_embedding\n",
        "    ratio = (count_not_found / total_count) * 100\n",
        "\n",
        "    print(\"Percentage of not recognised words (those we do not have an embedding for) : %.2f\" % ratio, \"%\")\n",
        "    # We return the embedded corpus\n",
        "    return inputs_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eq9ZzOR2Vbmj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the second version, that will be useful for models operating on a sequence of tokens, we do not average over the tokens of a sentence, but concatenate the embeddings of the tokens. Because our models need the same input size for every input, we must match the size of the longuest tweet of the corpus (105 tokens), and pad the shorter ones. This leads to a sparse matrix for the short tweets, but this model has the advantage of being simple."
      ]
    },
    {
      "metadata": {
        "id": "OMiE11xRWo0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def embed_corpus_2(emb_dict, corpus):\n",
        "\n",
        "    tweet_lengths = [len(tweet) for tweet in corpus]\n",
        "    max_len = np.max(np.array(tweet_lengths))\n",
        "\n",
        "    # Prepare container for tweet embeddings\n",
        "    inputs_ = torch.zeros((len(corpus), max_len, 100))\n",
        "\n",
        "    # Counter for debugging purposes\n",
        "    count_not_found = 0.\n",
        "    total_count = 0.\n",
        "\n",
        "    # We loop over all the tweets in the corpus\n",
        "    for idx, tweet in enumerate(corpus):\n",
        "        # and over all the words in a tweet\n",
        "        for idx2, word in enumerate(tweet):\n",
        "            total_count += 1\n",
        "            if word in emb_dict.keys():\n",
        "                inputs_[idx, idx2] = torch.Tensor(emb_dict[word])\n",
        "            else:\n",
        "                count_not_found += 1\n",
        "    ratio = (count_not_found / total_count) * 100\n",
        "\n",
        "    print(\"Percentage of not recognised words (those we do not have an embedding for) : %.2f\" % ratio, \"%\")\n",
        "    # We return the embedded corpus\n",
        "    return inputs_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-QNcAm9vVWy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data loaders"
      ]
    },
    {
      "metadata": {
        "id": "sPBsZnKoOtEH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We define a function data_loader that takes as inputs the embedded tweets and the corresponding labels for a given task, the batch size, the weight of the potential validation and test size, as well as the balancing option. It returns 3 pytorch Dataloader objects on which we will be able to train our models."
      ]
    },
    {
      "metadata": {
        "id": "Yuu6Id53vYQA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_loader(emb_corpus, labels, batch_size, random_seed, valid_size=0.1, \n",
        "                test_size=0.1, balancing=True):\n",
        "\n",
        "    \n",
        "    labels_ = torch.Tensor(labels)\n",
        "    \n",
        "    # Sending everything to GPU\n",
        "    labels_.to(device)\n",
        "    emb_corpus.to(device)\n",
        "    \n",
        "    # Create dataset pytorch object\n",
        "    dataset_ = torch.utils.data.TensorDataset(emb_corpus, labels_)\n",
        "\n",
        "    # Split to train / valid / test dataset\n",
        "    size_dataset = len(labels)\n",
        "    indices = list(range(size_dataset))\n",
        "    valid_split = int(np.floor(valid_size * size_dataset))\n",
        "    test_split = int(np.floor(test_size * size_dataset))\n",
        "\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Create lists of train/valid/test indices, to be provided to SubsetSampler \n",
        "    train_valid_idx, test_idx = indices[test_split:], indices[:test_split]\n",
        "    train_idx, valid_idx = train_valid_idx[valid_split:], train_valid_idx[:valid_split]\n",
        "\n",
        "    # Instantiate SubsetSamplers from list of indices.\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "    test_sampler = SubsetRandomSampler(test_idx)\n",
        "\n",
        "    # Valid and test loaders are not balanced\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        dataset_, batch_size=batch_size, sampler=valid_sampler)\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        dataset_, batch_size=batch_size, sampler=test_sampler)\n",
        "\n",
        "    # If balancing set to False, we just create a data loader from the train indices\n",
        "    if not balancing:\n",
        "        train_loader = torch.utils.data.DataLoader(\n",
        "            dataset_, batch_size=batch_size, sampler=train_sampler)\n",
        "\n",
        "        return train_loader, valid_loader, test_loader\n",
        "\n",
        "    # If there is balancing to do, we first extract the training samples \n",
        "    # according to the predefined indices, before using a weighted sampler\n",
        "    if balancing:\n",
        "        train_loader_unbalanced = torch.utils.data.DataLoader(\n",
        "            dataset_, batch_size=len(labels), sampler=train_sampler)\n",
        "        \n",
        "        # Get back training data from sampler\n",
        "        training_data, training_labels = next(iter(train_loader_unbalanced))\n",
        "        \n",
        "        train_dataset = torch.utils.data.TensorDataset(training_data, training_labels)\n",
        "\n",
        "        # WeightedSampler takes the list of weights as input\n",
        "        class_sample_count = np.array([len(np.where(training_labels == t)[0]) \n",
        "                                       for t in np.unique(training_labels)])\n",
        "        \n",
        "        weight = 1. / class_sample_count\n",
        "        samples_weight = np.array([weight[int(t)] for t in training_labels])\n",
        "\n",
        "        samples_weight = torch.from_numpy(samples_weight)\n",
        "        samples_weight = samples_weight.double()\n",
        "        balance_sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "        train_loader_balanced = DataLoader(train_dataset, batch_size=batch_size, \n",
        "                                           num_workers=1, sampler=balance_sampler)\n",
        "\n",
        "        return train_loader_balanced, valid_loader, test_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ZaI2QH25yh2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Some utils functions"
      ]
    },
    {
      "metadata": {
        "id": "rzdWcUB3RRKl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Accuracy : output and target expected to be lists of label integers"
      ]
    },
    {
      "metadata": {
        "id": "5QAaQeMSpfj8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def accuracy(output, target):\n",
        "    correct = (output == target)\n",
        "    acc = float(float(correct.sum()) /len(output) ) * 100\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jd8XHrAJRoqJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Recall and precision, computed from the confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "K0A0qUwuEaE8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def recall_precision(cm):\n",
        "    nb_classes = cm.shape[0]\n",
        "    recall = np.zeros(nb_classes)\n",
        "    precision = np.zeros(nb_classes)\n",
        "    for idx in range(nb_classes):\n",
        "        if (idx + 1) < nb_classes:\n",
        "            false_negative = np.concatenate((cm[idx, :idx], cm[idx, (idx + 1):]))\n",
        "            false_positive = np.concatenate((cm[:idx, idx], cm[(idx + 1):, idx]))\n",
        "        else:\n",
        "            false_negative = cm[idx, :idx]\n",
        "            false_positive = cm[:idx, idx]\n",
        "        \n",
        "        true_positive = cm[idx, idx]\n",
        "        \n",
        "        recall[idx] = true_positive / (true_positive + false_negative.sum())\n",
        "        precision[idx] = true_positive / (true_positive + false_positive.sum())\n",
        "    \n",
        "    return recall, precision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f_YHG0oxR80M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Compute F1-measure from recall and precision. Output is a list containing F1 measure from each class label"
      ]
    },
    {
      "metadata": {
        "id": "AYirWzYH21nG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def f1_measure(recall, precision):\n",
        "    f1 = 2 * (recall * precision) / (recall + precision)\n",
        "    return f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BEemB2QySFMa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Metrics function that wraps all the metrics defined above. The Confusion matrix is obtained with the sklearn corresponding function"
      ]
    },
    {
      "metadata": {
        "id": "oym0O1R_2ZdR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def metrics(prediction, target):\n",
        "    \n",
        "    # Number of correct predictions\n",
        "    acc = accuracy(prediction, target)\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(target, prediction)\n",
        "    \n",
        "    # Recall and precision\n",
        "    recall, precision = recall_precision(cm)\n",
        "    f1 = f1_measure(recall, precision)\n",
        "    \n",
        "    return acc, cm, recall, precision, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6wbLlQAZSX7p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We define an function that evaluates the performance of a model on a given dataloader. This will be usefull to evaluate a model on the validation and test sets. It outputs the metrics seen above."
      ]
    },
    {
      "metadata": {
        "id": "6RXptVQHqh0P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval(model, dataloader):\n",
        "\n",
        "  predictions = np.array(0)\n",
        "  targets = np.array(0)\n",
        "  \n",
        "  for batch_idx, (embedding, target) in enumerate(dataloader):    \n",
        "    \n",
        "    # If the model is on the GPU, don't forget to send the input \"embedding\" to \n",
        "    # the GPU too before computing the prediction\n",
        "    prediction = model(embedding.to(device)).detach()\n",
        "    \n",
        "    # We store the rounded values (integers) of the model output \n",
        "    predictions = np.append(predictions, np.round_(prediction.cpu().numpy()).astype(int))\n",
        "    targets = np.append(targets, target.numpy().astype(int))\n",
        "  \n",
        "  return metrics(predictions, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uT92eV35mvn9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model definitions"
      ]
    },
    {
      "metadata": {
        "id": "3KUywB8R0PxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## First model : a 3 hidden layers fully connected feed forward network"
      ]
    },
    {
      "metadata": {
        "id": "XlWNDS76Nmyd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FFNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        embedding_dim = 100\n",
        "        h_dim1 = 512\n",
        "        h_dim2 = 256\n",
        "        h_dim3 = 64\n",
        "        num_classes = 1\n",
        "\n",
        "        # hidden layers\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(in_features=embedding_dim, out_features=h_dim1, bias=True),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(in_features=h_dim1, out_features=h_dim2, bias=True),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(in_features=h_dim2, out_features=h_dim3, bias=True),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # output layer\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(in_features=h_dim3, out_features=num_classes, bias=True),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ui7_b5AVnNCk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "IQp4N0LqnDFc",
        "colab_type": "code",
        "outputId": "0f03983c-0708-49e9-e769-56dab989c624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3488
        }
      },
      "cell_type": "code",
      "source": [
        "#  <----------- Global variables for the NN and the training --------------->\n",
        "\n",
        "# we will train for N epochs (N times the model will see all the data)\n",
        "epochs = 100\n",
        "\n",
        "#  <----------- END Global variables for the NN and the training --------------->\n",
        "\n",
        "emb_corpus = embed_corpus(emb_dict, tokenized_corpus)\n",
        "\n",
        "train_loader, valid_loader, test_loader = data_loader(emb_corpus, label1, 32, 1)\n",
        "\n",
        "# Instantiate the model\n",
        "model_FFNN = FFNN().to(device)\n",
        "\n",
        "# we use the stochastic gradient descent (SGD) optimizer\n",
        "optimizer = optim.SGD(model_FFNN.parameters(), lr=0.5)\n",
        "\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss_history = []\n",
        "    acc_history = []\n",
        "    for batch_idx, (embedding, target) in enumerate(train_loader):\n",
        "\n",
        "        model_FFNN.train()\n",
        "\n",
        "        # we zero the gradients as they are not removed automatically\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # squeeze is needed as the predictions are initially size (batch size, 1) \n",
        "        # and we need to remove the dimension of size 1\n",
        "        predictions = model_FFNN(embedding.to(device)).squeeze(1)\n",
        "        loss = nn.BCELoss()(predictions, target.to(device))\n",
        "        \n",
        "        # For log purposes\n",
        "        loss_history.append(float(loss))\n",
        "        predictions = predictions.detach()\n",
        "        target = target.detach()\n",
        "        acc_history.append(accuracy(np.round_(predictions.cpu().numpy()).astype(int), \n",
        "                                    target.cpu().numpy().astype(int)))\n",
        "\n",
        "        # calculate the gradient of each parameter\n",
        "        loss.backward()\n",
        "\n",
        "        # update the parameters using the gradients and optimizer algorithm\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = np.array(loss_history).mean()\n",
        "    epoch_acc = np.array(acc_history).mean()\n",
        "\n",
        "    val_acc, cm, recall, precision, f1 = eval(model_FFNN, valid_loader)\n",
        "    print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.3f} | Train Acc: {epoch_acc:.2f}%')\n",
        "    print(\"Valid accuracy :\", val_acc)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of not recognised words (those we do not have an embedding for) : 3.35 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.675 | Train Acc: 56.91%\n",
            "Valid accuracy : 57.056603773584904\n",
            "| Epoch: 02 | Train Loss: 0.636 | Train Acc: 63.57%\n",
            "Valid accuracy : 73.28301886792453\n",
            "| Epoch: 03 | Train Loss: 0.618 | Train Acc: 65.92%\n",
            "Valid accuracy : 72.0754716981132\n",
            "| Epoch: 04 | Train Loss: 0.603 | Train Acc: 67.75%\n",
            "Valid accuracy : 72.15094339622642\n",
            "| Epoch: 05 | Train Loss: 0.595 | Train Acc: 67.56%\n",
            "Valid accuracy : 63.924528301886795\n",
            "| Epoch: 06 | Train Loss: 0.583 | Train Acc: 68.56%\n",
            "Valid accuracy : 74.33962264150942\n",
            "| Epoch: 07 | Train Loss: 0.579 | Train Acc: 70.00%\n",
            "Valid accuracy : 69.35849056603773\n",
            "| Epoch: 08 | Train Loss: 0.573 | Train Acc: 69.32%\n",
            "Valid accuracy : 69.13207547169812\n",
            "| Epoch: 09 | Train Loss: 0.563 | Train Acc: 70.35%\n",
            "Valid accuracy : 54.943396226415096\n",
            "| Epoch: 10 | Train Loss: 0.567 | Train Acc: 70.34%\n",
            "Valid accuracy : 69.0566037735849\n",
            "| Epoch: 11 | Train Loss: 0.569 | Train Acc: 69.90%\n",
            "Valid accuracy : 63.54716981132076\n",
            "| Epoch: 12 | Train Loss: 0.554 | Train Acc: 70.81%\n",
            "Valid accuracy : 71.24528301886792\n",
            "| Epoch: 13 | Train Loss: 0.562 | Train Acc: 70.79%\n",
            "Valid accuracy : 73.43396226415095\n",
            "| Epoch: 14 | Train Loss: 0.554 | Train Acc: 71.47%\n",
            "Valid accuracy : 70.11320754716981\n",
            "| Epoch: 15 | Train Loss: 0.552 | Train Acc: 70.80%\n",
            "Valid accuracy : 74.41509433962264\n",
            "| Epoch: 16 | Train Loss: 0.549 | Train Acc: 70.78%\n",
            "Valid accuracy : 69.28301886792453\n",
            "| Epoch: 17 | Train Loss: 0.545 | Train Acc: 71.68%\n",
            "Valid accuracy : 74.11320754716981\n",
            "| Epoch: 18 | Train Loss: 0.548 | Train Acc: 71.72%\n",
            "Valid accuracy : 57.73584905660377\n",
            "| Epoch: 19 | Train Loss: 0.546 | Train Acc: 71.69%\n",
            "Valid accuracy : 64.37735849056604\n",
            "| Epoch: 20 | Train Loss: 0.547 | Train Acc: 71.81%\n",
            "Valid accuracy : 71.77358490566039\n",
            "| Epoch: 21 | Train Loss: 0.539 | Train Acc: 72.35%\n",
            "Valid accuracy : 72.52830188679246\n",
            "| Epoch: 22 | Train Loss: 0.541 | Train Acc: 71.54%\n",
            "Valid accuracy : 71.24528301886792\n",
            "| Epoch: 23 | Train Loss: 0.535 | Train Acc: 72.07%\n",
            "Valid accuracy : 74.79245283018868\n",
            "| Epoch: 24 | Train Loss: 0.540 | Train Acc: 72.25%\n",
            "Valid accuracy : 61.13207547169811\n",
            "| Epoch: 25 | Train Loss: 0.533 | Train Acc: 72.99%\n",
            "Valid accuracy : 73.43396226415095\n",
            "| Epoch: 26 | Train Loss: 0.523 | Train Acc: 72.91%\n",
            "Valid accuracy : 75.09433962264151\n",
            "| Epoch: 27 | Train Loss: 0.523 | Train Acc: 73.03%\n",
            "Valid accuracy : 71.62264150943396\n",
            "| Epoch: 28 | Train Loss: 0.524 | Train Acc: 73.06%\n",
            "Valid accuracy : 71.69811320754717\n",
            "| Epoch: 29 | Train Loss: 0.519 | Train Acc: 73.71%\n",
            "Valid accuracy : 70.26415094339623\n",
            "| Epoch: 30 | Train Loss: 0.522 | Train Acc: 72.81%\n",
            "Valid accuracy : 75.24528301886792\n",
            "| Epoch: 31 | Train Loss: 0.517 | Train Acc: 73.46%\n",
            "Valid accuracy : 69.50943396226415\n",
            "| Epoch: 32 | Train Loss: 0.518 | Train Acc: 73.22%\n",
            "Valid accuracy : 70.33962264150944\n",
            "| Epoch: 33 | Train Loss: 0.519 | Train Acc: 73.16%\n",
            "Valid accuracy : 72.30188679245283\n",
            "| Epoch: 34 | Train Loss: 0.513 | Train Acc: 73.57%\n",
            "Valid accuracy : 73.66037735849056\n",
            "| Epoch: 35 | Train Loss: 0.504 | Train Acc: 74.02%\n",
            "Valid accuracy : 74.11320754716981\n",
            "| Epoch: 36 | Train Loss: 0.501 | Train Acc: 74.70%\n",
            "Valid accuracy : 69.20754716981132\n",
            "| Epoch: 37 | Train Loss: 0.517 | Train Acc: 73.50%\n",
            "Valid accuracy : 66.26415094339623\n",
            "| Epoch: 38 | Train Loss: 0.516 | Train Acc: 73.91%\n",
            "Valid accuracy : 73.28301886792453\n",
            "| Epoch: 39 | Train Loss: 0.515 | Train Acc: 73.12%\n",
            "Valid accuracy : 69.13207547169812\n",
            "| Epoch: 40 | Train Loss: 0.502 | Train Acc: 74.40%\n",
            "Valid accuracy : 69.20754716981132\n",
            "| Epoch: 41 | Train Loss: 0.502 | Train Acc: 74.24%\n",
            "Valid accuracy : 74.41509433962264\n",
            "| Epoch: 42 | Train Loss: 0.505 | Train Acc: 74.37%\n",
            "Valid accuracy : 72.9056603773585\n",
            "| Epoch: 43 | Train Loss: 0.500 | Train Acc: 74.79%\n",
            "Valid accuracy : 66.71698113207547\n",
            "| Epoch: 44 | Train Loss: 0.497 | Train Acc: 75.23%\n",
            "Valid accuracy : 73.50943396226415\n",
            "| Epoch: 45 | Train Loss: 0.500 | Train Acc: 74.79%\n",
            "Valid accuracy : 69.43396226415094\n",
            "| Epoch: 46 | Train Loss: 0.496 | Train Acc: 74.82%\n",
            "Valid accuracy : 70.26415094339623\n",
            "| Epoch: 47 | Train Loss: 0.493 | Train Acc: 74.24%\n",
            "Valid accuracy : 63.54716981132076\n",
            "| Epoch: 48 | Train Loss: 0.490 | Train Acc: 75.16%\n",
            "Valid accuracy : 71.47169811320755\n",
            "| Epoch: 49 | Train Loss: 0.492 | Train Acc: 75.04%\n",
            "Valid accuracy : 69.58490566037736\n",
            "| Epoch: 50 | Train Loss: 0.485 | Train Acc: 75.42%\n",
            "Valid accuracy : 69.13207547169812\n",
            "| Epoch: 51 | Train Loss: 0.489 | Train Acc: 74.87%\n",
            "Valid accuracy : 69.28301886792453\n",
            "| Epoch: 52 | Train Loss: 0.484 | Train Acc: 75.59%\n",
            "Valid accuracy : 69.43396226415094\n",
            "| Epoch: 53 | Train Loss: 0.484 | Train Acc: 75.47%\n",
            "Valid accuracy : 61.81132075471698\n",
            "| Epoch: 54 | Train Loss: 0.481 | Train Acc: 75.32%\n",
            "Valid accuracy : 70.26415094339623\n",
            "| Epoch: 55 | Train Loss: 0.481 | Train Acc: 75.83%\n",
            "Valid accuracy : 67.47169811320755\n",
            "| Epoch: 56 | Train Loss: 0.487 | Train Acc: 75.33%\n",
            "Valid accuracy : 70.18867924528301\n",
            "| Epoch: 57 | Train Loss: 0.479 | Train Acc: 75.84%\n",
            "Valid accuracy : 69.58490566037736\n",
            "| Epoch: 58 | Train Loss: 0.483 | Train Acc: 75.53%\n",
            "Valid accuracy : 59.01886792452831\n",
            "| Epoch: 59 | Train Loss: 0.465 | Train Acc: 76.83%\n",
            "Valid accuracy : 68.90566037735849\n",
            "| Epoch: 60 | Train Loss: 0.470 | Train Acc: 76.53%\n",
            "Valid accuracy : 72.22641509433963\n",
            "| Epoch: 61 | Train Loss: 0.466 | Train Acc: 76.65%\n",
            "Valid accuracy : 66.33962264150944\n",
            "| Epoch: 62 | Train Loss: 0.460 | Train Acc: 76.54%\n",
            "Valid accuracy : 74.79245283018868\n",
            "| Epoch: 63 | Train Loss: 0.474 | Train Acc: 75.21%\n",
            "Valid accuracy : 56.83018867924529\n",
            "| Epoch: 64 | Train Loss: 0.466 | Train Acc: 76.26%\n",
            "Valid accuracy : 73.9622641509434\n",
            "| Epoch: 65 | Train Loss: 0.456 | Train Acc: 77.22%\n",
            "Valid accuracy : 70.26415094339623\n",
            "| Epoch: 66 | Train Loss: 0.455 | Train Acc: 77.52%\n",
            "Valid accuracy : 69.81132075471697\n",
            "| Epoch: 67 | Train Loss: 0.457 | Train Acc: 77.33%\n",
            "Valid accuracy : 62.71698113207547\n",
            "| Epoch: 68 | Train Loss: 0.461 | Train Acc: 76.60%\n",
            "Valid accuracy : 72.0\n",
            "| Epoch: 69 | Train Loss: 0.445 | Train Acc: 77.01%\n",
            "Valid accuracy : 73.73584905660377\n",
            "| Epoch: 70 | Train Loss: 0.448 | Train Acc: 77.06%\n",
            "Valid accuracy : 68.67924528301886\n",
            "| Epoch: 71 | Train Loss: 0.450 | Train Acc: 77.21%\n",
            "Valid accuracy : 63.39622641509434\n",
            "| Epoch: 72 | Train Loss: 0.459 | Train Acc: 76.92%\n",
            "Valid accuracy : 67.32075471698113\n",
            "| Epoch: 73 | Train Loss: 0.453 | Train Acc: 77.37%\n",
            "Valid accuracy : 71.24528301886792\n",
            "| Epoch: 74 | Train Loss: 0.439 | Train Acc: 78.04%\n",
            "Valid accuracy : 72.45283018867924\n",
            "| Epoch: 75 | Train Loss: 0.445 | Train Acc: 77.66%\n",
            "Valid accuracy : 71.62264150943396\n",
            "| Epoch: 76 | Train Loss: 0.449 | Train Acc: 77.10%\n",
            "Valid accuracy : 73.05660377358491\n",
            "| Epoch: 77 | Train Loss: 0.439 | Train Acc: 78.00%\n",
            "Valid accuracy : 69.50943396226415\n",
            "| Epoch: 78 | Train Loss: 0.438 | Train Acc: 78.15%\n",
            "Valid accuracy : 71.54716981132076\n",
            "| Epoch: 79 | Train Loss: 0.457 | Train Acc: 76.91%\n",
            "Valid accuracy : 59.01886792452831\n",
            "| Epoch: 80 | Train Loss: 0.439 | Train Acc: 77.86%\n",
            "Valid accuracy : 72.37735849056604\n",
            "| Epoch: 81 | Train Loss: 0.434 | Train Acc: 78.33%\n",
            "Valid accuracy : 69.66037735849056\n",
            "| Epoch: 82 | Train Loss: 0.441 | Train Acc: 77.51%\n",
            "Valid accuracy : 73.73584905660377\n",
            "| Epoch: 83 | Train Loss: 0.429 | Train Acc: 78.29%\n",
            "Valid accuracy : 64.83018867924528\n",
            "| Epoch: 84 | Train Loss: 0.422 | Train Acc: 78.62%\n",
            "Valid accuracy : 71.16981132075472\n",
            "| Epoch: 85 | Train Loss: 0.432 | Train Acc: 78.97%\n",
            "Valid accuracy : 68.0754716981132\n",
            "| Epoch: 86 | Train Loss: 0.423 | Train Acc: 78.83%\n",
            "Valid accuracy : 74.33962264150942\n",
            "| Epoch: 87 | Train Loss: 0.425 | Train Acc: 78.50%\n",
            "Valid accuracy : 67.24528301886792\n",
            "| Epoch: 88 | Train Loss: 0.423 | Train Acc: 79.10%\n",
            "Valid accuracy : 72.67924528301887\n",
            "| Epoch: 89 | Train Loss: 0.419 | Train Acc: 78.59%\n",
            "Valid accuracy : 68.60377358490565\n",
            "| Epoch: 90 | Train Loss: 0.412 | Train Acc: 78.87%\n",
            "Valid accuracy : 67.16981132075472\n",
            "| Epoch: 91 | Train Loss: 0.413 | Train Acc: 79.65%\n",
            "Valid accuracy : 71.84905660377359\n",
            "| Epoch: 92 | Train Loss: 0.416 | Train Acc: 79.11%\n",
            "Valid accuracy : 72.75471698113208\n",
            "| Epoch: 93 | Train Loss: 0.409 | Train Acc: 79.63%\n",
            "Valid accuracy : 70.71698113207547\n",
            "| Epoch: 94 | Train Loss: 0.406 | Train Acc: 79.81%\n",
            "Valid accuracy : 71.69811320754717\n",
            "| Epoch: 95 | Train Loss: 0.407 | Train Acc: 80.16%\n",
            "Valid accuracy : 64.83018867924528\n",
            "| Epoch: 96 | Train Loss: 0.413 | Train Acc: 80.17%\n",
            "Valid accuracy : 68.15094339622641\n",
            "| Epoch: 97 | Train Loss: 0.407 | Train Acc: 80.55%\n",
            "Valid accuracy : 73.66037735849056\n",
            "| Epoch: 98 | Train Loss: 0.407 | Train Acc: 80.40%\n",
            "Valid accuracy : 71.32075471698113\n",
            "| Epoch: 99 | Train Loss: 0.417 | Train Acc: 79.70%\n",
            "Valid accuracy : 70.41509433962264\n",
            "| Epoch: 100 | Train Loss: 0.398 | Train Acc: 80.66%\n",
            "Valid accuracy : 70.94339622641509\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b72XBChQrl85",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test"
      ]
    },
    {
      "metadata": {
        "id": "7bMBIhp7nZR5",
        "colab_type": "code",
        "outputId": "17587f32-c6d6-4190-d1b8-3bc9e8502b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "acc_test, cm_test, recall_test, precision_test, f1_test = eval(model_FFNN, test_loader)\n",
        "print(\"Accuracy on test dataset : %.2f\" % acc_test, \"%\")\n",
        "print(\"F1-measure on test dataset : \", f1_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test dataset : 71.25 %\n",
            "F1-measure on test dataset :  [0.76923077 0.61861862]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jjj0fp393k_n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## A second model : CNN"
      ]
    },
    {
      "metadata": {
        "id": "MJv2d_h63oLv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As we can see above, the FFNN detects offensive tweets with an accuracy of roughly 71%, which is not too bad for this naive model. However, this came after an important amount of preprocessing. In this part, I'll try to improve this detection accuracy by using a different kind of neural network : a CNN."
      ]
    },
    {
      "metadata": {
        "id": "cR_ESPLH4Fen",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def embed_corpus_2(emb_dict, corpus):\n",
        "\n",
        "    tweet_lengths = [len(tweet) for tweet in corpus]\n",
        "    max_len = np.max(np.array(tweet_lengths))\n",
        "\n",
        "    # Prepare container for tweet embeddings\n",
        "    inputs_ = torch.zeros((len(corpus), max_len, 100))\n",
        "\n",
        "    # Counter for debugging purposes\n",
        "    count_not_found = 0.\n",
        "    total_count = 0.\n",
        "\n",
        "    # We loop over all the tweets in the corpus\n",
        "    for idx, tweet in enumerate(corpus):\n",
        "        # and over all the words in a tweet\n",
        "        for idx2, word in enumerate(tweet):\n",
        "            total_count += 1\n",
        "            if word in emb_dict.keys():\n",
        "                inputs_[idx, idx2] = torch.Tensor(emb_dict[word])\n",
        "            else:\n",
        "                count_not_found += 1\n",
        "    ratio = (count_not_found / total_count) * 100\n",
        "\n",
        "    print(\"Percentage of not recognised words (those we do not have an embedding for) : %.2f\" % ratio, \"%\")\n",
        "    # We return the embedded corpus\n",
        "    return inputs_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ytswTyxOAyrw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, out_channels, window_size, output_dim, dropout):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # in_channels -- 1 text channel\n",
        "        # out_channels -- the number of output channels\n",
        "        # kernel_size is (window size x embedding dim)\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=out_channels, kernel_size=(window_size, embedding_dim))\n",
        "\n",
        "        # the dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # the output layer\n",
        "        self.fc = nn.Linear(out_channels, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch size, max sent length, embedding dim)\n",
        "\n",
        "        # We unsqueeze one dimension to give space to the coming convolution channels\n",
        "        embedded = x.unsqueeze(1)\n",
        "\n",
        "        # (batch size, 1, max sent length, embedding dim)\n",
        "\n",
        "        feature_maps = self.conv(embedded)\n",
        "\n",
        "        # (batch size, n filters, max input length - window size +1)\n",
        "\n",
        "        feature_maps = feature_maps.squeeze(3)\n",
        "\n",
        "        feature_maps = F.relu(feature_maps)\n",
        "\n",
        "        # the max pooling layer\n",
        "        pooled = F.max_pool1d(feature_maps, feature_maps.shape[2])\n",
        "\n",
        "        pooled = pooled.squeeze(2)\n",
        "\n",
        "        # (batch size, n_filters)\n",
        "\n",
        "        dropped = self.dropout(pooled)\n",
        "\n",
        "        preds = self.fc(dropped)\n",
        "\n",
        "        preds = torch.sigmoid(preds)\n",
        "        \n",
        "        return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IC_pLe87BL-z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "Bp4BpU0QA87V",
        "colab_type": "code",
        "outputId": "ad4f1c25-60d4-4884-c59b-dc0c51311bfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3488
        }
      },
      "cell_type": "code",
      "source": [
        "epochs=100\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "\n",
        "#the hyperparameters specific to CNN\n",
        "\n",
        "# we define the number of filters\n",
        "N_OUT_CHANNELS = 100\n",
        "\n",
        "# we define the window size\n",
        "WINDOW_SIZE = 1\n",
        "\n",
        "# we apply the dropout with the probability 0.5\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model_CNN = CNN(EMBEDDING_DIM, N_OUT_CHANNELS, WINDOW_SIZE, OUTPUT_DIM, DROPOUT).to(device)\n",
        "\n",
        "optimizer = optim.SGD(model_CNN.parameters(), lr=0.01)\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "emb_corpus = embed_corpus_2(emb_dict, tokenized_corpus)\n",
        "train_loader, valid_loader, test_loader = data_loader(emb_corpus, label1, 32, 1)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss_history = []\n",
        "    acc_history = []\n",
        "    for batch_idx, (embedding, target) in enumerate(train_loader):\n",
        "\n",
        "        model_CNN.train()\n",
        "\n",
        "        # we zero the gradients as they are not removed automatically\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # squeeze is needed as the predictions are initially size (batch size, 1) \n",
        "        # and we need to remove the dimension of size 1\n",
        "        predictions = model_CNN(embedding.to(device)).squeeze(1)   \n",
        "        loss = nn.BCELoss()(predictions, target.to(device))\n",
        "        loss_history.append(float(loss))\n",
        "        \n",
        "        predictions = predictions.detach()\n",
        "        target = target.detach()\n",
        "        acc_history.append(accuracy(np.round_(predictions.cpu().numpy()).astype(int), \n",
        "                                    target.cpu().numpy().astype(int)))\n",
        "        \n",
        "        # calculate the gradient of each parameter\n",
        "        loss.backward()\n",
        "\n",
        "        # update the parameters using the gradients and optimizer algorithm\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = np.array(loss_history).mean()\n",
        "    epoch_acc = np.array(acc_history).mean()\n",
        "\n",
        "    val_acc, cm, recall, precision, f1 = eval(model_CNN, valid_loader)\n",
        "    print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.3f} | Train Acc: {epoch_acc:.2f}%')\n",
        "    print(f'---> Valid accuracy : {val_acc:.2f}%')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of not recognised words (those we do not have an embedding for) : 3.35 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.697 | Train Acc: 51.98%\n",
            "---> Valid accuracy : 43.25%\n",
            "| Epoch: 02 | Train Loss: 0.684 | Train Acc: 55.95%\n",
            "---> Valid accuracy : 58.11%\n",
            "| Epoch: 03 | Train Loss: 0.672 | Train Acc: 59.25%\n",
            "---> Valid accuracy : 63.55%\n",
            "| Epoch: 04 | Train Loss: 0.654 | Train Acc: 62.98%\n",
            "---> Valid accuracy : 64.68%\n",
            "| Epoch: 05 | Train Loss: 0.619 | Train Acc: 66.58%\n",
            "---> Valid accuracy : 67.70%\n",
            "| Epoch: 06 | Train Loss: 0.584 | Train Acc: 70.42%\n",
            "---> Valid accuracy : 70.19%\n",
            "| Epoch: 07 | Train Loss: 0.569 | Train Acc: 70.86%\n",
            "---> Valid accuracy : 73.28%\n",
            "| Epoch: 08 | Train Loss: 0.558 | Train Acc: 71.71%\n",
            "---> Valid accuracy : 73.43%\n",
            "| Epoch: 09 | Train Loss: 0.558 | Train Acc: 71.71%\n",
            "---> Valid accuracy : 72.83%\n",
            "| Epoch: 10 | Train Loss: 0.547 | Train Acc: 72.60%\n",
            "---> Valid accuracy : 75.17%\n",
            "| Epoch: 11 | Train Loss: 0.534 | Train Acc: 73.17%\n",
            "---> Valid accuracy : 73.58%\n",
            "| Epoch: 12 | Train Loss: 0.539 | Train Acc: 73.23%\n",
            "---> Valid accuracy : 74.49%\n",
            "| Epoch: 13 | Train Loss: 0.532 | Train Acc: 74.06%\n",
            "---> Valid accuracy : 75.02%\n",
            "| Epoch: 14 | Train Loss: 0.532 | Train Acc: 73.28%\n",
            "---> Valid accuracy : 73.74%\n",
            "| Epoch: 15 | Train Loss: 0.530 | Train Acc: 73.72%\n",
            "---> Valid accuracy : 73.74%\n",
            "| Epoch: 16 | Train Loss: 0.531 | Train Acc: 74.19%\n",
            "---> Valid accuracy : 74.42%\n",
            "| Epoch: 17 | Train Loss: 0.523 | Train Acc: 74.51%\n",
            "---> Valid accuracy : 73.81%\n",
            "| Epoch: 18 | Train Loss: 0.527 | Train Acc: 74.00%\n",
            "---> Valid accuracy : 75.62%\n",
            "| Epoch: 19 | Train Loss: 0.521 | Train Acc: 74.69%\n",
            "---> Valid accuracy : 75.47%\n",
            "| Epoch: 20 | Train Loss: 0.525 | Train Acc: 73.77%\n",
            "---> Valid accuracy : 74.72%\n",
            "| Epoch: 21 | Train Loss: 0.513 | Train Acc: 75.28%\n",
            "---> Valid accuracy : 75.17%\n",
            "| Epoch: 22 | Train Loss: 0.522 | Train Acc: 74.75%\n",
            "---> Valid accuracy : 74.19%\n",
            "| Epoch: 23 | Train Loss: 0.524 | Train Acc: 74.50%\n",
            "---> Valid accuracy : 74.26%\n",
            "| Epoch: 24 | Train Loss: 0.514 | Train Acc: 75.07%\n",
            "---> Valid accuracy : 74.57%\n",
            "| Epoch: 25 | Train Loss: 0.507 | Train Acc: 75.62%\n",
            "---> Valid accuracy : 76.00%\n",
            "| Epoch: 26 | Train Loss: 0.509 | Train Acc: 75.38%\n",
            "---> Valid accuracy : 75.92%\n",
            "| Epoch: 27 | Train Loss: 0.511 | Train Acc: 74.74%\n",
            "---> Valid accuracy : 75.25%\n",
            "| Epoch: 28 | Train Loss: 0.511 | Train Acc: 75.23%\n",
            "---> Valid accuracy : 75.92%\n",
            "| Epoch: 29 | Train Loss: 0.515 | Train Acc: 75.11%\n",
            "---> Valid accuracy : 75.09%\n",
            "| Epoch: 30 | Train Loss: 0.514 | Train Acc: 75.21%\n",
            "---> Valid accuracy : 74.49%\n",
            "| Epoch: 31 | Train Loss: 0.508 | Train Acc: 75.38%\n",
            "---> Valid accuracy : 75.77%\n",
            "| Epoch: 32 | Train Loss: 0.506 | Train Acc: 75.62%\n",
            "---> Valid accuracy : 74.94%\n",
            "| Epoch: 33 | Train Loss: 0.504 | Train Acc: 75.98%\n",
            "---> Valid accuracy : 76.23%\n",
            "| Epoch: 34 | Train Loss: 0.506 | Train Acc: 75.76%\n",
            "---> Valid accuracy : 75.40%\n",
            "| Epoch: 35 | Train Loss: 0.501 | Train Acc: 75.88%\n",
            "---> Valid accuracy : 76.45%\n",
            "| Epoch: 36 | Train Loss: 0.504 | Train Acc: 75.78%\n",
            "---> Valid accuracy : 76.98%\n",
            "| Epoch: 37 | Train Loss: 0.505 | Train Acc: 75.53%\n",
            "---> Valid accuracy : 75.85%\n",
            "| Epoch: 38 | Train Loss: 0.498 | Train Acc: 76.04%\n",
            "---> Valid accuracy : 75.17%\n",
            "| Epoch: 39 | Train Loss: 0.497 | Train Acc: 75.97%\n",
            "---> Valid accuracy : 76.68%\n",
            "| Epoch: 40 | Train Loss: 0.497 | Train Acc: 76.01%\n",
            "---> Valid accuracy : 75.09%\n",
            "| Epoch: 41 | Train Loss: 0.492 | Train Acc: 76.51%\n",
            "---> Valid accuracy : 76.08%\n",
            "| Epoch: 42 | Train Loss: 0.493 | Train Acc: 76.40%\n",
            "---> Valid accuracy : 74.34%\n",
            "| Epoch: 43 | Train Loss: 0.496 | Train Acc: 75.86%\n",
            "---> Valid accuracy : 75.47%\n",
            "| Epoch: 44 | Train Loss: 0.496 | Train Acc: 76.24%\n",
            "---> Valid accuracy : 76.68%\n",
            "| Epoch: 45 | Train Loss: 0.495 | Train Acc: 76.13%\n",
            "---> Valid accuracy : 76.45%\n",
            "| Epoch: 46 | Train Loss: 0.503 | Train Acc: 75.62%\n",
            "---> Valid accuracy : 75.17%\n",
            "| Epoch: 47 | Train Loss: 0.492 | Train Acc: 76.77%\n",
            "---> Valid accuracy : 74.34%\n",
            "| Epoch: 48 | Train Loss: 0.500 | Train Acc: 75.97%\n",
            "---> Valid accuracy : 74.57%\n",
            "| Epoch: 49 | Train Loss: 0.489 | Train Acc: 76.34%\n",
            "---> Valid accuracy : 74.79%\n",
            "| Epoch: 50 | Train Loss: 0.497 | Train Acc: 76.17%\n",
            "---> Valid accuracy : 76.30%\n",
            "| Epoch: 51 | Train Loss: 0.492 | Train Acc: 76.73%\n",
            "---> Valid accuracy : 75.02%\n",
            "| Epoch: 52 | Train Loss: 0.489 | Train Acc: 76.72%\n",
            "---> Valid accuracy : 75.17%\n",
            "| Epoch: 53 | Train Loss: 0.480 | Train Acc: 77.33%\n",
            "---> Valid accuracy : 74.42%\n",
            "| Epoch: 54 | Train Loss: 0.483 | Train Acc: 76.97%\n",
            "---> Valid accuracy : 76.23%\n",
            "| Epoch: 55 | Train Loss: 0.490 | Train Acc: 76.67%\n",
            "---> Valid accuracy : 75.17%\n",
            "| Epoch: 56 | Train Loss: 0.494 | Train Acc: 76.68%\n",
            "---> Valid accuracy : 76.91%\n",
            "| Epoch: 57 | Train Loss: 0.483 | Train Acc: 76.96%\n",
            "---> Valid accuracy : 74.64%\n",
            "| Epoch: 58 | Train Loss: 0.491 | Train Acc: 76.73%\n",
            "---> Valid accuracy : 75.77%\n",
            "| Epoch: 59 | Train Loss: 0.484 | Train Acc: 76.87%\n",
            "---> Valid accuracy : 76.83%\n",
            "| Epoch: 60 | Train Loss: 0.487 | Train Acc: 76.83%\n",
            "---> Valid accuracy : 75.25%\n",
            "| Epoch: 61 | Train Loss: 0.482 | Train Acc: 77.45%\n",
            "---> Valid accuracy : 77.58%\n",
            "| Epoch: 62 | Train Loss: 0.479 | Train Acc: 76.88%\n",
            "---> Valid accuracy : 75.02%\n",
            "| Epoch: 63 | Train Loss: 0.485 | Train Acc: 76.89%\n",
            "---> Valid accuracy : 76.98%\n",
            "| Epoch: 64 | Train Loss: 0.474 | Train Acc: 77.71%\n",
            "---> Valid accuracy : 76.15%\n",
            "| Epoch: 65 | Train Loss: 0.471 | Train Acc: 77.92%\n",
            "---> Valid accuracy : 75.09%\n",
            "| Epoch: 66 | Train Loss: 0.478 | Train Acc: 76.77%\n",
            "---> Valid accuracy : 74.72%\n",
            "| Epoch: 67 | Train Loss: 0.485 | Train Acc: 76.77%\n",
            "---> Valid accuracy : 77.21%\n",
            "| Epoch: 68 | Train Loss: 0.466 | Train Acc: 78.04%\n",
            "---> Valid accuracy : 75.70%\n",
            "| Epoch: 69 | Train Loss: 0.479 | Train Acc: 77.49%\n",
            "---> Valid accuracy : 75.92%\n",
            "| Epoch: 70 | Train Loss: 0.478 | Train Acc: 77.25%\n",
            "---> Valid accuracy : 74.94%\n",
            "| Epoch: 71 | Train Loss: 0.470 | Train Acc: 77.98%\n",
            "---> Valid accuracy : 75.25%\n",
            "| Epoch: 72 | Train Loss: 0.478 | Train Acc: 77.20%\n",
            "---> Valid accuracy : 75.47%\n",
            "| Epoch: 73 | Train Loss: 0.481 | Train Acc: 77.17%\n",
            "---> Valid accuracy : 75.32%\n",
            "| Epoch: 74 | Train Loss: 0.477 | Train Acc: 77.57%\n",
            "---> Valid accuracy : 75.25%\n",
            "| Epoch: 75 | Train Loss: 0.472 | Train Acc: 78.03%\n",
            "---> Valid accuracy : 77.28%\n",
            "| Epoch: 76 | Train Loss: 0.483 | Train Acc: 77.10%\n",
            "---> Valid accuracy : 74.34%\n",
            "| Epoch: 77 | Train Loss: 0.475 | Train Acc: 77.82%\n",
            "---> Valid accuracy : 75.92%\n",
            "| Epoch: 78 | Train Loss: 0.466 | Train Acc: 78.31%\n",
            "---> Valid accuracy : 76.23%\n",
            "| Epoch: 79 | Train Loss: 0.474 | Train Acc: 77.83%\n",
            "---> Valid accuracy : 76.23%\n",
            "| Epoch: 80 | Train Loss: 0.476 | Train Acc: 77.93%\n",
            "---> Valid accuracy : 76.00%\n",
            "| Epoch: 81 | Train Loss: 0.475 | Train Acc: 77.56%\n",
            "---> Valid accuracy : 76.30%\n",
            "| Epoch: 82 | Train Loss: 0.464 | Train Acc: 78.44%\n",
            "---> Valid accuracy : 76.45%\n",
            "| Epoch: 83 | Train Loss: 0.468 | Train Acc: 78.36%\n",
            "---> Valid accuracy : 75.47%\n",
            "| Epoch: 84 | Train Loss: 0.470 | Train Acc: 78.05%\n",
            "---> Valid accuracy : 76.60%\n",
            "| Epoch: 85 | Train Loss: 0.462 | Train Acc: 78.19%\n",
            "---> Valid accuracy : 75.40%\n",
            "| Epoch: 86 | Train Loss: 0.459 | Train Acc: 78.73%\n",
            "---> Valid accuracy : 74.79%\n",
            "| Epoch: 87 | Train Loss: 0.462 | Train Acc: 78.45%\n",
            "---> Valid accuracy : 76.30%\n",
            "| Epoch: 88 | Train Loss: 0.458 | Train Acc: 78.66%\n",
            "---> Valid accuracy : 75.55%\n",
            "| Epoch: 89 | Train Loss: 0.471 | Train Acc: 78.41%\n",
            "---> Valid accuracy : 76.91%\n",
            "| Epoch: 90 | Train Loss: 0.459 | Train Acc: 78.97%\n",
            "---> Valid accuracy : 76.60%\n",
            "| Epoch: 91 | Train Loss: 0.449 | Train Acc: 79.31%\n",
            "---> Valid accuracy : 76.00%\n",
            "| Epoch: 92 | Train Loss: 0.456 | Train Acc: 78.77%\n",
            "---> Valid accuracy : 75.77%\n",
            "| Epoch: 93 | Train Loss: 0.452 | Train Acc: 78.84%\n",
            "---> Valid accuracy : 77.13%\n",
            "| Epoch: 94 | Train Loss: 0.458 | Train Acc: 79.14%\n",
            "---> Valid accuracy : 75.92%\n",
            "| Epoch: 95 | Train Loss: 0.456 | Train Acc: 78.82%\n",
            "---> Valid accuracy : 77.58%\n",
            "| Epoch: 96 | Train Loss: 0.461 | Train Acc: 78.83%\n",
            "---> Valid accuracy : 73.81%\n",
            "| Epoch: 97 | Train Loss: 0.469 | Train Acc: 78.29%\n",
            "---> Valid accuracy : 76.00%\n",
            "| Epoch: 98 | Train Loss: 0.454 | Train Acc: 78.80%\n",
            "---> Valid accuracy : 76.00%\n",
            "| Epoch: 99 | Train Loss: 0.456 | Train Acc: 78.64%\n",
            "---> Valid accuracy : 76.38%\n",
            "| Epoch: 100 | Train Loss: 0.463 | Train Acc: 78.29%\n",
            "---> Valid accuracy : 75.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gPamjXA1nBMx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test"
      ]
    },
    {
      "metadata": {
        "id": "9Ye17EQUD6bj",
        "colab_type": "code",
        "outputId": "365f6b7f-f7b3-4a6b-f075-b07ef4118f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "acc_test, cm_test, recall_test, precision_test, f1_test = eval(model_CNN, test_loader)\n",
        "print(\"Accuracy on test dataset : %.2f\" % acc_test, \"%\")\n",
        "print(\"F1-measure on test dataset : \", f1_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test dataset : 75.55 %\n",
            "F1-measure on test dataset :  [0.81008206 0.65677966]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iNIP4sbdGRMO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Conclusion : with this simple CNN model, we improved :\n",
        " \n",
        "\n",
        "*   The detection accuracy from 74% (FFNN) to roughly **76%**.\n",
        "*   The F1 values also improved quite well : from [0.79 ; 0.62] to **[0.81 ; 0.65]**\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DsAtuKYXqfNM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## A third model : bidirectional LSTM"
      ]
    },
    {
      "metadata": {
        "id": "YI8H2mMCfUD0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's now try a RNN . Because of the architecture of the LSTM, we need to redefine a little bit the evaluation function, to discard potential batches that would not have the same size as the configured batch_size."
      ]
    },
    {
      "metadata": {
        "id": "-V6OV23omY38",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_lstm(model, dataloader, batch_size):\n",
        "    \n",
        "    predictions = np.array(0)\n",
        "    targets = np.array(0)\n",
        "    \n",
        "    for batch_idx, (embedding, target) in enumerate(dataloader):\n",
        "        # With LSTM, we will have troubles if the batch size changes \n",
        "        # (for example on the last batch. We discard it)\n",
        "        if embedding.shape[0] != batch_size:\n",
        "            continue\n",
        "        \n",
        "        embedding = embedding.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        prediction = model(embedding).detach().cpu()\n",
        "        \n",
        "        predictions = np.append(predictions, np.round_(prediction.cpu().numpy()).astype(int))\n",
        "        targets = np.append(targets, target.cpu().numpy().astype(int))\n",
        "    \n",
        "    return metrics(predictions, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7WnIUEA_qjGA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BiLSTM(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, dropout, seq_len):\n",
        "        super(BiLSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = 32\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim * 2.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
        "                            dropout=dropout, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.linear = nn.Linear(seq_len * hidden_dim * 2, output_dim)\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly\n",
        "        # why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        return (autograd.Variable(torch.zeros(2, self.batch_size, self.hidden_dim).to(device)),\n",
        "                autograd.Variable(torch.zeros(2, self.batch_size, self.hidden_dim).to(device)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.shape[0] != self.batch_size:\n",
        "            pad = torch.zeros((self.batch_size - x.shape[0], x.shape[1], x.shape[2])).to(device)\n",
        "            x = torch.cat((x, pad), dim=0)\n",
        "        # Shape of x  torch.Size([32, 105, 100])\n",
        "        # Shape of LSTM out  torch.Size([32, 105, 40])\n",
        "        \n",
        "        # lstm out should be (seq_len, batch, num_directions * hidden_size)\n",
        "        # elements of self.hidden should be (num_layers * num_directions, batch, hidden_size)\n",
        "        \n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        lstm_out = lstm_out.contiguous()\n",
        "        lstm_out = lstm_out.view(-1, self.seq_len * 2 * self.hidden_dim)\n",
        "\n",
        "        tag_space = self.linear(lstm_out)\n",
        "        tag_scores = torch.sigmoid(tag_space)\n",
        "        return tag_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sYVWkhFdqto9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "eh8E9d_2qsc4",
        "colab_type": "code",
        "outputId": "0933e2ba-2008-4276-8604-5f32af4fface",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs=10\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 10\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "SEQ_LEN = 105\n",
        "\n",
        "model_BiLSTM = BiLSTM(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT, SEQ_LEN).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model_BiLSTM.parameters())\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "emb_corpus = embed_corpus_2(emb_dict, tokenized_corpus)\n",
        "train_loader, valid_loader, test_loader = data_loader(emb_corpus, label1, batch_size, 1)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss_history = []\n",
        "    acc_history = []\n",
        "    for batch_idx, (embedding, target) in enumerate(train_loader):\n",
        "        \n",
        "        model_BiLSTM.train()\n",
        "\n",
        "        # we zero the gradients as they are not removed automatically\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Also, we need to clear out the hidden state of the LSTM,\n",
        "        # detaching it from its history on the last instance.\n",
        "        model_BiLSTM.hidden = model_BiLSTM.init_hidden()\n",
        "\n",
        "        # Send input data to GPU\n",
        "        embedding = embedding.to(device)\n",
        "        \n",
        "        # squeeze is needed as the predictions are initially size (batch size, 1) \n",
        "        # and we need to remove the dimension of size 1\n",
        "        predictions = model_BiLSTM(embedding).squeeze(1)\n",
        "        loss = nn.BCELoss()(predictions, target.to(device))\n",
        "        loss_history.append(float(loss))\n",
        "        \n",
        "        predictions = predictions.detach()\n",
        "        target = target.detach()\n",
        "        acc_history.append(accuracy(np.round_(predictions.cpu().numpy()).astype(int), \n",
        "                                    target.cpu().numpy().astype(int)))       \n",
        "        \n",
        "        # calculate the gradient of each parameter\n",
        "        loss.backward()\n",
        "\n",
        "        # update the parameters using the gradients and optimizer algorithm\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = np.array(loss_history).mean()\n",
        "    epoch_acc = np.array(acc_history).mean()\n",
        "    \n",
        "    val_acc, cm, recall, precision, f1 = eval_lstm(model_BiLSTM, valid_loader, batch_size)\n",
        "    print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.3f} | Train Acc: {epoch_acc:.2f}%')\n",
        "    print(f'---> Valid accuracy : {val_acc:.2f}%')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Percentage of not recognised words (those we do not have an embedding for) : 3.35 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.633 | Train Acc: 62.83%\n",
            "---> Valid accuracy : 71.21%\n",
            "| Epoch: 02 | Train Loss: 0.523 | Train Acc: 73.95%\n",
            "---> Valid accuracy : 73.34%\n",
            "| Epoch: 03 | Train Loss: 0.492 | Train Acc: 76.03%\n",
            "---> Valid accuracy : 75.78%\n",
            "| Epoch: 04 | Train Loss: 0.462 | Train Acc: 78.69%\n",
            "---> Valid accuracy : 73.88%\n",
            "| Epoch: 05 | Train Loss: 0.448 | Train Acc: 79.31%\n",
            "---> Valid accuracy : 76.16%\n",
            "| Epoch: 06 | Train Loss: 0.437 | Train Acc: 79.80%\n",
            "---> Valid accuracy : 73.80%\n",
            "| Epoch: 07 | Train Loss: 0.416 | Train Acc: 81.22%\n",
            "---> Valid accuracy : 77.30%\n",
            "| Epoch: 08 | Train Loss: 0.397 | Train Acc: 83.02%\n",
            "---> Valid accuracy : 74.03%\n",
            "| Epoch: 09 | Train Loss: 0.385 | Train Acc: 83.18%\n",
            "---> Valid accuracy : 75.40%\n",
            "| Epoch: 10 | Train Loss: 0.371 | Train Acc: 84.18%\n",
            "---> Valid accuracy : 76.16%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1Z0SUrpAoWUh",
        "colab_type": "code",
        "outputId": "aacf603a-5bfd-41a5-8cdd-4d1d9a65b8d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "acc_test, cm_test, recall_test, precision_test, f1_test = eval_lstm(model_BiLSTM, test_loader, batch_size)\n",
        "print(\"Accuracy on test dataset : %.2f\" % acc_test, \"%\")\n",
        "print(\"F1-measure on test dataset : \", f1_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test dataset : 75.02 %\n",
            "F1-measure on test dataset :  [0.80751174 0.64425163]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5VkoXuNmzaQJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Conclusion : on only 10 epochs with a naive dense layer output, this model achieves almost the same accuracy as the CNN model. We also see that this model overfits very quickly. Let's try to combine Bi-LSTM and convolutions now."
      ]
    },
    {
      "metadata": {
        "id": "AHAOBXBZzmj-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Last model : Bi-directional LSTM + convolutions"
      ]
    },
    {
      "metadata": {
        "id": "94RH1IlUzrt2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BiLSTMConv(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, dropout, seq_len, \n",
        "                 channels, window_size, batch_size):\n",
        "        super(BiLSTMConv, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
        "                            dropout=dropout, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=channels, kernel_size=(window_size, 2 * hidden_dim))\n",
        "        \n",
        "        # the dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.linear = nn.Linear(channels, output_dim)\n",
        "        \n",
        "    def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly\n",
        "        # why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        return (autograd.Variable(torch.zeros(2, self.batch_size, self.hidden_dim).to(device)),\n",
        "                autograd.Variable(torch.zeros(2, self.batch_size, self.hidden_dim).to(device)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.shape[0] != self.batch_size:\n",
        "            pad = torch.zeros((self.batch_size - x.shape[0], x.shape[1], x.shape[2])).to(device)\n",
        "            x = torch.cat((x, pad), dim=0)\n",
        "        # Shape of x  torch.Size([32, 105, 100])\n",
        "        # Shape of LSTM out  torch.Size([32, 105, 40])\n",
        "        \n",
        "        # lstm out should be (seq_len, batch, num_directions * hidden_size)\n",
        "        # elements of self.hidden should be (num_layers * num_directions, batch, hidden_size)\n",
        "        \n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        \n",
        "        #lstm_out = lstm_out.contiguous()\n",
        "        #lstm_out = lstm_out.view(-1, self.seq_len * 2 * self.hidden_dim)\n",
        "\n",
        "        # make space for convolution channels\n",
        "        lstm_out = lstm_out.unsqueeze(1)\n",
        "        lstm_out = F.relu(lstm_out)\n",
        "        \n",
        "        \n",
        "        conv_out = self.conv(lstm_out)\n",
        "        \n",
        "        conv_out = conv_out.squeeze(3)\n",
        "        \n",
        "        pooled = F.max_pool1d(conv_out, conv_out.shape[2])\n",
        "        \n",
        "        pooled = pooled.squeeze(2)\n",
        "        \n",
        "        # (batch size, n_filters)\n",
        "        dropped = self.dropout(pooled)\n",
        "        \n",
        "        preds = self.linear(dropped)\n",
        "        preds = torch.sigmoid(preds)\n",
        "\n",
        "        return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dTp3Yglyd25l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training"
      ]
    },
    {
      "metadata": {
        "id": "N0wo00TCd4CE",
        "colab_type": "code",
        "outputId": "8157f645-3d8c-4cd2-f1f2-23a15b3e1cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs=10\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 10\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "SEQ_LEN = 105\n",
        "CHANNELS = 16\n",
        "WINDOW_SIZE = 1\n",
        "\n",
        "model_BiLSTMConv = BiLSTMConv(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT, \n",
        "                   SEQ_LEN, CHANNELS, WINDOW_SIZE, batch_size).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model_BiLSTMConv.parameters())\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "emb_corpus = embed_corpus_2(emb_dict, tokenized_corpus)\n",
        "train_loader, valid_loader, test_loader = data_loader(emb_corpus, label1, batch_size, 1)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss_history = []\n",
        "    acc_history = []\n",
        "    for batch_idx, (embedding, target) in enumerate(train_loader):\n",
        "        \n",
        "        model_BiLSTMConv.train()\n",
        "\n",
        "        # we zero the gradients as they are not removed automatically\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Also, we need to clear out the hidden state of the LSTM,\n",
        "        # detaching it from its history on the last instance.\n",
        "        model_BiLSTMConv.hidden = model_BiLSTMConv.init_hidden()\n",
        "\n",
        "        # Send input data to GPU\n",
        "        embedding = embedding.to(device)\n",
        "        \n",
        "        # squeeze is needed as the predictions are initially size (batch size, 1) and we need to remove the dimension of size 1\n",
        "        predictions = model_BiLSTMConv(embedding).squeeze(1)\n",
        "        loss = nn.BCELoss()(predictions, target.to(device))\n",
        "        loss_history.append(float(loss))\n",
        "        \n",
        "        predictions = predictions.detach()\n",
        "        target = target.detach()\n",
        "        acc_history.append(accuracy(np.round_(predictions.cpu().numpy()).astype(int), \n",
        "                                    target.cpu().numpy().astype(int)))     \n",
        "\n",
        "        # calculate the gradient of each parameter\n",
        "        loss.backward()\n",
        "\n",
        "        # update the parameters using the gradients and optimizer algorithm\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = np.array(loss_history).mean()\n",
        "    epoch_acc = np.array(acc_history).mean()\n",
        "    \n",
        "    val_acc, cm, recall, precision, f1 = eval_lstm(model_BiLSTMConv, valid_loader, batch_size)\n",
        "    print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.3f} | Train Acc: {epoch_acc:.2f}%')\n",
        "    print(f'---> Valid accuracy : {val_acc:.2f}%')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Percentage of not recognised words (those we do not have an embedding for) : 3.35 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.636 | Train Acc: 62.70%\n",
            "---> Valid accuracy : 76.69%\n",
            "| Epoch: 02 | Train Loss: 0.527 | Train Acc: 74.53%\n",
            "---> Valid accuracy : 73.80%\n",
            "| Epoch: 03 | Train Loss: 0.505 | Train Acc: 76.50%\n",
            "---> Valid accuracy : 75.55%\n",
            "| Epoch: 04 | Train Loss: 0.499 | Train Acc: 76.70%\n",
            "---> Valid accuracy : 76.01%\n",
            "| Epoch: 05 | Train Loss: 0.474 | Train Acc: 78.79%\n",
            "---> Valid accuracy : 76.09%\n",
            "| Epoch: 06 | Train Loss: 0.482 | Train Acc: 78.08%\n",
            "---> Valid accuracy : 77.30%\n",
            "| Epoch: 07 | Train Loss: 0.469 | Train Acc: 78.97%\n",
            "---> Valid accuracy : 76.62%\n",
            "| Epoch: 08 | Train Loss: 0.450 | Train Acc: 80.08%\n",
            "---> Valid accuracy : 77.38%\n",
            "| Epoch: 09 | Train Loss: 0.442 | Train Acc: 80.35%\n",
            "---> Valid accuracy : 77.08%\n",
            "| Epoch: 10 | Train Loss: 0.439 | Train Acc: 80.81%\n",
            "---> Valid accuracy : 77.46%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pjkJRPJNgSyR",
        "colab_type": "code",
        "outputId": "3fe97a30-ce9f-4d01-c6c2-f20212ec092a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "acc_test, cm_test, recall_test, precision_test, f1_test = eval_lstm(model_BiLSTMConv, test_loader, batch_size)\n",
        "print(\"Accuracy on test dataset : %.2f\" % acc_test, \"%\")\n",
        "print(\"F1-measure on test dataset : \", f1_test)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test dataset : 75.48 %\n",
            "F1-measure on test dataset :  [0.81169591 0.64847162]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OEh33FmkmYOq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These are the best results obtained so far, we will thus tuse this model to generate predictions for the challenge!"
      ]
    },
    {
      "metadata": {
        "id": "EBiVexNOnb4V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sub task a"
      ]
    },
    {
      "metadata": {
        "id": "x_X5QqsHum8f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test prediction generation"
      ]
    },
    {
      "metadata": {
        "id": "cUc5AozEnf3R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because the dataset are new for the challenge prediction (different from the training), we need to import the specific tokenized corpus as well as the new embedding dictionnaries. Indeed, in the new datasets, there may be some new vocabulary word that we have not encountered before, so we need their embedding from the GloVe file."
      ]
    },
    {
      "metadata": {
        "id": "5NKuolwQn6nm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A pre requisite for the execution of further cells is the import of a few .txt file that have been previsouly generated from the given dataset. Please import :\n",
        "\n",
        "*   \"test_corpus_tweets_a.txt\"\n",
        "*   \"test_corpus_tweets_b.txt\"\n",
        "*   \"test_corpus_tweets_c.txt\"\n",
        "*   \"emb_dic_a.txt\"\n",
        "*   \"emb_dic_b.txt\"\n",
        "*   \"emb_dic_c.txt\"\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "8vTxpVRupss-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Some data management before predictions"
      ]
    },
    {
      "metadata": {
        "id": "vdCP44OSup-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the cleaned tokenized corpus back\n",
        "with open(\"test_corpus_tweets_a.txt\", \"r\") as file:\n",
        "    tmp_a = file.read().splitlines()\n",
        "\n",
        "\n",
        "tokenized_corpus_a = [[token for token in sentence.split(' ')][:-1] for sentence in tmp_a]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E5wc7pTCuzIf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_path = 'emb_dic_a.txt'\n",
        "emb_dict_a = extract_dic(embedding_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6FxH51Tuzyy",
        "colab_type": "code",
        "outputId": "67fe7919-71d9-4f0d-b592-666c710bd2e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "emb_corpus_a = embed_corpus_2(emb_dict_a, tokenized_corpus_a)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of not recognised words (those we do not have an embedding for) : 17.55 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FtbT4E7gw1qI",
        "colab_type": "code",
        "outputId": "b7082cb8-73f3-4f68-b6c4-0d0f9f0432f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(emb_corpus_a.shape)\n",
        "\n",
        "# We need to make this a multiple of batch_size = 32. We padd with zeros. \n",
        "# We will discard the results after.\n",
        "\n",
        "sent_pad = torch.zeros((4, 66, 100))\n",
        "\n",
        "emb_corpus_a = torch.cat((emb_corpus_a, sent_pad), dim=0)\n",
        "\n",
        "print(emb_corpus_a.shape)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([860, 66, 100])\n",
            "torch.Size([864, 66, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n1EUUefupzGt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  We now prepare the input to the model and make predictions"
      ]
    },
    {
      "metadata": {
        "id": "yebMLN96vjwv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make batches of 32 : \n",
        "\n",
        "input_a = emb_corpus_a.view(-1, 32, 66, 100)\n",
        "\n",
        "# Preparing a container for the results\n",
        "prediction_a = torch.zeros((int(864/32),32))\n",
        "\n",
        "for batch in range(26):\n",
        "    output = model_BiLSTMConv(torch.Tensor(input_a[batch]).to(device))\n",
        "    prediction_a[batch] = output.cpu().detach().squeeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SCXD4AjNz3Pp",
        "colab_type": "code",
        "outputId": "d920dbe5-3a24-4c0b-ff38-221587d2074f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "cell_type": "code",
      "source": [
        "# reshape prediction_a and dicard the last elements corresponding to the padding\n",
        "prediction_a = prediction_a.view(-1)[:-4]\n",
        "print(prediction_a.shape)\n",
        "\n",
        "# Getting back the np.array, and round the result to have 0 or 1\n",
        "prediction_a = prediction_a.numpy()\n",
        "prediction_a = np.round_(prediction_a).astype(int)\n",
        "print(prediction_a)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([860])\n",
            "[0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
            " 0 1 1 1 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 0\n",
            " 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1\n",
            " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0\n",
            " 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
            " 1 0 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1\n",
            " 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0\n",
            " 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 1 0 0 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0\n",
            " 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 1\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 1 1 0 0 0 1 1 1 0 0 0 1\n",
            " 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
            " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 0 1 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
            " 1 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1\n",
            " 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 1 0 1 0 0 1 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 1\n",
            " 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 0\n",
            " 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E4hRytc-p6Hh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now have to translate our integer vector shaped prediction to a csv file composed of \"OFF\" and \"NOT\" labels. To do this, we need to get back the id of the tweets from the original file. Please import the file \"testset-taska.tsv\"."
      ]
    },
    {
      "metadata": {
        "id": "v3ejjgrI5uYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_a_letters = [\"OFF\" if element == 1 else \"NOT\" for element in prediction_a]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HHxdaHJK5-BA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataframe_a = pd.read_csv('testset-taska.tsv', sep=\"\\t\", header=0)\n",
        "id_a = dataframe_a[\"id\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qsJVBZdf666F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_dataframe = pd.DataFrame(prediction_a_letters, index=id_a)\n",
        "pred_dataframe.to_csv(path_or_buf =\"pred_a.csv\", header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NDAsuMmVqcaZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The prediction is now available in the files section (refresh it to see it), and ready to be downloaded."
      ]
    },
    {
      "metadata": {
        "id": "2ypSV0zmuODz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sub task b"
      ]
    },
    {
      "metadata": {
        "id": "LulN38SRqpci",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our models have been trained on the whole dataset, that is to say for sub task A. Now we want to train for sub task B, thus we need a subdataset containing the relevant tweets for this specific task. The corresponding files have already been imported in the beginning of this notebook"
      ]
    },
    {
      "metadata": {
        "id": "T9Tjd03erHhU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because we are dealing with the training data, we get back are original embedding dictionnary"
      ]
    },
    {
      "metadata": {
        "id": "HPQ3CRdrun90",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_path = 'emb_dic.txt'\n",
        "emb_dict = extract_dic(embedding_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qzQQbB3u34n",
        "colab_type": "code",
        "outputId": "ddb802e6-2c80-4cad-bed6-b0f932a858a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "emb_corpus_b = embed_corpus_2(emb_dict, tokenized_corpus_b)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of not recognised words (those we do not have an embedding for) : 2.84 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u7CZ6wTLvbSr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "dimH5AB1vc1Q",
        "colab_type": "code",
        "outputId": "69fb1880-699e-4358-b74e-31f8aa55dff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs=12\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 10\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "SEQ_LEN = 105\n",
        "CHANNELS = 16\n",
        "WINDOW_SIZE = 1\n",
        "\n",
        "model_BiLSTMConv = BiLSTMConv(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT, \n",
        "                   SEQ_LEN, CHANNELS, WINDOW_SIZE, batch_size).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model_BiLSTMConv.parameters())\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "train_loader, valid_loader, test_loader = data_loader(emb_corpus_b, label_b, batch_size, 1, valid_size=0.1, test_size=0.1)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss_history = []\n",
        "    acc_history = []\n",
        "    for batch_idx, (embedding, target) in enumerate(train_loader):\n",
        "        \n",
        "        model_BiLSTMConv.train()\n",
        "\n",
        "        # we zero the gradients as they are not removed automatically\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Also, we need to clear out the hidden state of the LSTM,\n",
        "        # detaching it from its history on the last instance.\n",
        "        model_BiLSTMConv.hidden = model_BiLSTMConv.init_hidden()\n",
        "\n",
        "        # Send input data to GPU\n",
        "        embedding = embedding.to(device)\n",
        "        \n",
        "        # squeeze is needed as the predictions are initially size (batch size, 1) and we need to remove the dimension of size 1\n",
        "        # Have to transpose batch and sequence dimensions for nn.LSTM\n",
        "        predictions = model_BiLSTMConv(embedding).squeeze(1)\n",
        "        loss = nn.BCELoss()(predictions, target.to(device))\n",
        "        loss_history.append(float(loss))\n",
        "        \n",
        "        predictions = predictions.detach()\n",
        "        target = target.detach()\n",
        "        acc_history.append(accuracy(np.round_(predictions.cpu().numpy()).astype(int), \n",
        "                                    target.cpu().numpy().astype(int)))     \n",
        "\n",
        "        # calculate the gradient of each parameter\n",
        "        loss.backward()\n",
        "\n",
        "        # update the parameters using the gradients and optimizer algorithm\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = np.array(loss_history).mean()\n",
        "    epoch_acc = np.array(acc_history).mean()\n",
        "\n",
        "    val_acc, cm, recall, precision, f1 = eval_lstm(model_BiLSTMConv, valid_loader, batch_size)\n",
        "    print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.3f} | Train Acc: {epoch_acc:.2f}%')\n",
        "    print(f'---> Valid accuracy : {val_acc:.2f}%')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 0.688 | Train Acc: 54.03%\n",
            "---> Valid accuracy : 72.52%\n",
            "| Epoch: 02 | Train Loss: 0.664 | Train Acc: 62.05%\n",
            "---> Valid accuracy : 73.21%\n",
            "| Epoch: 03 | Train Loss: 0.626 | Train Acc: 65.99%\n",
            "---> Valid accuracy : 69.98%\n",
            "| Epoch: 04 | Train Loss: 0.592 | Train Acc: 69.80%\n",
            "---> Valid accuracy : 61.66%\n",
            "| Epoch: 05 | Train Loss: 0.572 | Train Acc: 71.22%\n",
            "---> Valid accuracy : 65.82%\n",
            "| Epoch: 06 | Train Loss: 0.536 | Train Acc: 74.06%\n",
            "---> Valid accuracy : 68.13%\n",
            "| Epoch: 07 | Train Loss: 0.535 | Train Acc: 74.40%\n",
            "---> Valid accuracy : 66.74%\n",
            "| Epoch: 08 | Train Loss: 0.486 | Train Acc: 77.56%\n",
            "---> Valid accuracy : 77.37%\n",
            "| Epoch: 09 | Train Loss: 0.439 | Train Acc: 81.16%\n",
            "---> Valid accuracy : 67.21%\n",
            "| Epoch: 10 | Train Loss: 0.403 | Train Acc: 84.43%\n",
            "---> Valid accuracy : 71.82%\n",
            "| Epoch: 11 | Train Loss: 0.348 | Train Acc: 87.44%\n",
            "---> Valid accuracy : 75.06%\n",
            "| Epoch: 12 | Train Loss: 0.291 | Train Acc: 90.34%\n",
            "---> Valid accuracy : 75.06%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DC9AjNw8wFm0",
        "colab_type": "code",
        "outputId": "25ed725d-8ea0-4b63-ced9-e4a118a8e465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "acc_test, cm_test, recall_test, precision_test, f1_test = eval_lstm(model_BiLSTMConv, test_loader, batch_size)\n",
        "print(\"Accuracy on test dataset : %.2f\" % acc_test, \"%\")\n",
        "print(\"F1-measure on test dataset : \", f1_test)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test dataset : 76.91 %\n",
            "F1-measure on test dataset :  [0.28571429 0.86225895]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fNLCRCkpzx0h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test sub_task_b"
      ]
    },
    {
      "metadata": {
        "id": "phV7q1BC4oX7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now that the model is trained for task b, we can predict the output for the challenge sub task b, the same way as for task a."
      ]
    },
    {
      "metadata": {
        "id": "LuNeHW3kz0xx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the cleaned tokenized corpus back\n",
        "with open(\"test_corpus_tweets_b.txt\", \"r\") as file:\n",
        "    tmp_b = file.read().splitlines()\n",
        "\n",
        "tokenized_corpus_b = [[token for token in sentence.split(' ')][:-1] for sentence in tmp_b]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ztnVx-bH1dVl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_path = 'emb_dic_b.txt'\n",
        "emb_dict_b = extract_dic(embedding_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bbbbStoY1OQC",
        "colab_type": "code",
        "outputId": "8f39e764-f901-4439-b8c1-7bde398f6a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "emb_corpus_b = embed_corpus_2(emb_dict_b, tokenized_corpus_b)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of not recognised words (those we do not have an embedding for) : 6.25 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W9br2-j21mWq",
        "colab_type": "code",
        "outputId": "936c561a-5193-42da-d1e8-b643de9093af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(emb_corpus_b.shape)\n",
        "\n",
        "# It is already a mutliple of batchsize 16"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([240, 59, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_rrPtHw5132K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make batches of 16 : \n",
        "\n",
        "input_b = emb_corpus_b.view(-1, 16, 59, 100)\n",
        "\n",
        "# Preparing a container for the results\n",
        "prediction_b = torch.zeros((int(240/16),16))\n",
        "\n",
        "for batch in range(15):\n",
        "    output = model_BiLSTMConv(torch.Tensor(input_b[batch]).to(device))\n",
        "    prediction_b[batch] = output.cpu().detach().squeeze(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_XNi1h5I2J7o",
        "colab_type": "code",
        "outputId": "8e8e2a59-6181-4e7e-dff8-c4025b45211b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "cell_type": "code",
      "source": [
        "# reshape prediction_a and dicard the last elements corresponding to the padding\n",
        "prediction_b = prediction_b.view(-1)\n",
        "print(prediction_b.shape)\n",
        "\n",
        "# Getting back the np.array, and round the result to have 0 or 1\n",
        "prediction_b = prediction_b.numpy()\n",
        "prediction_b = np.round_(prediction_b).astype(int)\n",
        "print(prediction_b)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([240])\n",
            "[1 1 0 1 0 1 1 1 0 1 1 0 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 1\n",
            " 0 0 1 1 1 1 0 0 1 1 0 0 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 0 0 1 1 1 0 1 0 0\n",
            " 1 1 0 0 0 0 1 1 1 1 0 0 1 1 0 0 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 0\n",
            " 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 1 1 0 1 0\n",
            " 0 1 1 1 0 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 0 0 0 1 0 1\n",
            " 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 1 0 1\n",
            " 1 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p6qK7-HR2X8r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_b_letters = [\"TIN\" if element == 1 else \"UNT\" for element in prediction_b]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pnbO0LUp2d98",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataframe_b = pd.read_csv('testset-taskb.tsv', sep=\"\\t\", header=0)\n",
        "id_b = dataframe_b[\"id\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5G_vHkhR2xq7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_dataframe = pd.DataFrame(prediction_b_letters, index=id_b)\n",
        "pred_dataframe.to_csv(path_or_buf =\"pred_b.csv\", header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5UvDQZSs5DEP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The predictions for task b can be found in the \"files\"!"
      ]
    },
    {
      "metadata": {
        "id": "-GFIHcYN9rtg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sub task C : a little modification of architecture"
      ]
    },
    {
      "metadata": {
        "id": "F4GT3XjiBkJ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_path = 'emb_dic.txt'\n",
        "emb_dict = extract_dic(embedding_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oflX06LQBvSZ",
        "colab_type": "code",
        "outputId": "2dabf380-7bc3-444e-c70c-61c30c2d61b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "emb_corpus_c = embed_corpus_2(emb_dict, tokenized_corpus_c)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of not recognised words (those we do not have an embedding for) : 2.79 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7F5ps54U9ts9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will operate a slight modification to the network to have 4 neurons in the output layer instead of 1. We will have to change the activation function (from ReLU() to Softmax()) and adapt the Loss function too."
      ]
    },
    {
      "metadata": {
        "id": "Qgcwvo8g-AC8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BiLSTMConv4(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, dropout, seq_len, \n",
        "                 channels, window_size, batch_size):\n",
        "        super(BiLSTMConv, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim,\n",
        "                            dropout=dropout, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden = self.init_hidden()\n",
        "        \n",
        "        self.conv = nn.Conv2d(in_channels=1, out_channels=channels, kernel_size=(window_size, 2 * hidden_dim))\n",
        "        \n",
        "        # the dropout layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.linear = nn.Linear(channels, output_dim)\n",
        "        \n",
        "    def init_hidden(self):\n",
        "        # Before we've done anything, we dont have any hidden state.\n",
        "        # Refer to the Pytorch documentation to see exactly\n",
        "        # why they have this dimensionality.\n",
        "        # The axes semantics are (num_layers * num_directions, minibatch_size, hidden_dim)\n",
        "        return (autograd.Variable(torch.zeros(2, self.batch_size, self.hidden_dim).to(device)),\n",
        "                autograd.Variable(torch.zeros(2, self.batch_size, self.hidden_dim).to(device)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.shape[0] != self.batch_size:\n",
        "            pad = torch.zeros((self.batch_size - x.shape[0], x.shape[1], x.shape[2])).to(device)\n",
        "            x = torch.cat((x, pad), dim=0)\n",
        "        # Shape of x  torch.Size([32, 105, 100])\n",
        "        # Shape of LSTM out  torch.Size([32, 105, 40])\n",
        "        \n",
        "        # lstm out should be (seq_len, batch, num_directions * hidden_size)\n",
        "        # elements of self.hidden should be (num_layers * num_directions, batch, hidden_size)\n",
        "        \n",
        "        lstm_out, self.hidden = self.lstm(x, self.hidden)\n",
        "        \n",
        "        #lstm_out = lstm_out.contiguous()\n",
        "        #lstm_out = lstm_out.view(-1, self.seq_len * 2 * self.hidden_dim)\n",
        "\n",
        "        # make space for convolution channels\n",
        "        lstm_out = lstm_out.unsqueeze(1)\n",
        "        lstm_out = F.relu(lstm_out)\n",
        "        \n",
        "        \n",
        "        conv_out = self.conv(lstm_out)\n",
        "        \n",
        "        conv_out = conv_out.squeeze(3)\n",
        "        \n",
        "        pooled = F.max_pool1d(conv_out, conv_out.shape[2])\n",
        "        \n",
        "        pooled = pooled.squeeze(2)\n",
        "        \n",
        "        # (batch size, n_filters)\n",
        "        dropped = self.dropout(pooled)\n",
        "        \n",
        "        preds = self.linear(dropped)\n",
        "\n",
        "        return preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g50XCE3Z529K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Because we now output 4 values instead of one, the evaluation function has to be adjusted."
      ]
    },
    {
      "metadata": {
        "id": "_8nrEFEE_GHq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_lstm2(model, dataloader, batch_size):\n",
        "    \n",
        "    predictions = np.array(0)\n",
        "    targets = np.array(0)\n",
        "    \n",
        "    for batch_idx, (embedding, target) in enumerate(dataloader):\n",
        "        # With LSTM, we will have troubles if the batch size changes \n",
        "        # (for example on the last batch. We discard it)\n",
        "        if embedding.shape[0] != batch_size:\n",
        "            continue\n",
        "        \n",
        "        embedding = embedding.to(device)\n",
        "        target = target.to(device)\n",
        "        \n",
        "        # Here we have to take the softmax of the predictions first\n",
        "        prediction = torch.softmax(model(embedding).detach().cpu(), dim=1)\n",
        "        prediction = prediction.cpu().numpy()\n",
        "        prediction = np.argmax(prediction, axis=1)\n",
        "        \n",
        "        predictions = np.append(predictions, prediction.astype(int))\n",
        "        targets = np.append(targets, target.cpu().numpy().astype(int))\n",
        "    \n",
        "    return metrics(predictions, targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eFG5_Iwu-Xb3",
        "colab_type": "code",
        "outputId": "9d54d794-efd3-47ce-b6d0-055d4a58b2c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "epochs=10\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 10\n",
        "OUTPUT_DIM = 3\n",
        "DROPOUT = 0.5\n",
        "SEQ_LEN = 105\n",
        "CHANNELS = 16\n",
        "WINDOW_SIZE = 1\n",
        "\n",
        "model_BiLSTMConv = BiLSTMConv(EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT, \n",
        "                   SEQ_LEN, CHANNELS, WINDOW_SIZE, batch_size).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model_BiLSTMConv.parameters())\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader, valid_loader, test_loader = data_loader(emb_corpus_c, label_c, batch_size, 1)\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss_history = []\n",
        "    acc_history = []\n",
        "    for batch_idx, (embedding, target) in enumerate(train_loader):\n",
        "        \n",
        "        model_BiLSTMConv.train()\n",
        "\n",
        "        # we zero the gradients as they are not removed automatically\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Also, we need to clear out the hidden state of the LSTM,\n",
        "        # detaching it from its history on the last instance.\n",
        "        model_BiLSTMConv.hidden = model_BiLSTMConv.init_hidden()\n",
        "\n",
        "        # Send input data to GPU\n",
        "        embedding = embedding.to(device)\n",
        "        \n",
        "        if target.shape[0] != batch_size:\n",
        "            pad = torch.zeros(batch_size - target.shape[0])\n",
        "            target = torch.cat((target, pad), dim=0)\n",
        "            \n",
        "        # squeeze is needed as the predictions are initially size (batch size, 1) and we need to remove the dimension of size 1\n",
        "        # Have to transpose batch and sequence dimensions for nn.LSTM\n",
        "        predictions = model_BiLSTMConv(embedding).squeeze(1)\n",
        "        loss = nn.CrossEntropyLoss()(predictions, target.long().to(device))\n",
        "        loss_history.append(float(loss))\n",
        "        \n",
        "        predictions = torch.softmax(predictions.detach(), dim=1)\n",
        "        predictions = np.argmax(predictions.cpu().numpy(), axis=1)\n",
        "        target = target.detach()\n",
        "        acc_history.append(accuracy(predictions.astype(int), \n",
        "                                    target.cpu().numpy().astype(int)))     \n",
        "\n",
        "        # calculate the gradient of each parameter\n",
        "        loss.backward()\n",
        "\n",
        "        # update the parameters using the gradients and optimizer algorithm\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = np.array(loss_history).mean()\n",
        "    epoch_acc = np.array(acc_history).mean()\n",
        "    \n",
        "    \n",
        "    val_acc, cm, recall, precision, f1 = eval_lstm2(model_BiLSTMConv, valid_loader, batch_size)\n",
        "    print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.3f} | Train Acc: {epoch_acc:.2f}%' )\n",
        "    print(f'---> Valid accuracy : {val_acc:.2f}%')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:46: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 1.096 | Train Acc: 36.82%\n",
            "---> Valid accuracy : 32.73%\n",
            "| Epoch: 02 | Train Loss: 1.065 | Train Acc: 46.52%\n",
            "---> Valid accuracy : 56.62%\n",
            "| Epoch: 03 | Train Loss: 1.013 | Train Acc: 51.03%\n",
            "---> Valid accuracy : 60.78%\n",
            "| Epoch: 04 | Train Loss: 0.977 | Train Acc: 53.16%\n",
            "---> Valid accuracy : 65.45%\n",
            "| Epoch: 05 | Train Loss: 0.966 | Train Acc: 54.19%\n",
            "---> Valid accuracy : 66.23%\n",
            "| Epoch: 06 | Train Loss: 0.956 | Train Acc: 54.83%\n",
            "---> Valid accuracy : 69.09%\n",
            "| Epoch: 07 | Train Loss: 0.947 | Train Acc: 58.51%\n",
            "---> Valid accuracy : 70.13%\n",
            "| Epoch: 08 | Train Loss: 0.937 | Train Acc: 57.60%\n",
            "---> Valid accuracy : 67.01%\n",
            "| Epoch: 09 | Train Loss: 0.925 | Train Acc: 59.99%\n",
            "---> Valid accuracy : 71.95%\n",
            "| Epoch: 10 | Train Loss: 0.911 | Train Acc: 60.70%\n",
            "---> Valid accuracy : 64.94%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tVpz5o8pLkcJ",
        "colab_type": "code",
        "outputId": "47d602a6-bb5c-4990-fb02-87e028c00aac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "acc_test, cm_test, recall_test, precision_test, f1_test = eval_lstm2(model_BiLSTMConv, test_loader, batch_size)\n",
        "print(\"Accuracy on test dataset : %.2f\" % acc_test, \"%\")\n",
        "print(\"F1-measure on test dataset : \", f1_test)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test dataset : 67.79 %\n",
            "F1-measure on test dataset :  [0.21978022 0.81263158 0.56862745]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9LbDmN0bMKVS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test task C"
      ]
    },
    {
      "metadata": {
        "id": "5A-40g1YMMDP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the cleaned tokenized corpus back\n",
        "with open(\"test_corpus_tweets_c.txt\", \"r\") as file:\n",
        "    tmp_c = file.read().splitlines()\n",
        "\n",
        "tokenized_corpus_c = [[token for token in sentence.split(' ')][:-1] for sentence in tmp_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6Ea-6V0ND3-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_path = 'emb_dic_c.txt'\n",
        "emb_dict_c = extract_dic(embedding_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hw24j5w1NKoZ",
        "colab_type": "code",
        "outputId": "9a110415-7ea8-4f39-edc6-25816bf2e6cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "emb_corpus_c = embed_corpus_2(emb_dict_c, tokenized_corpus_c)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Percentage of not recognised words (those we do not have an embedding for) : 6.04 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UT3xFqQBNUB1",
        "colab_type": "code",
        "outputId": "1a5f2ff9-126b-40c1-a1d1-d44ec6cf1ad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(emb_corpus_c.shape)\n",
        "\n",
        "# We need to make it a multiple of the batchsize:\n",
        "\n",
        "pad = torch.zeros((11, 58, 100))\n",
        "emb_corpus_c = torch.cat((emb_corpus_c, pad), dim=0)\n",
        "print(emb_corpus_c.shape)\n",
        "# It is already a mutliple of batchsize 16"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([213, 58, 100])\n",
            "torch.Size([224, 58, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2Oo1wCO1OFM9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make batches of 16 : \n",
        "\n",
        "input_c = emb_corpus_c.view(-1, 16, 58, 100)\n",
        "\n",
        "# Preparing a container for the results\n",
        "prediction_c = np.zeros((int(224/16),16))\n",
        "\n",
        "for batch in range(14):\n",
        "    output = model_BiLSTMConv(torch.Tensor(input_c[batch]).to(device))\n",
        "    output = torch.softmax(output, dim=1)\n",
        "    output = np.argmax(output.cpu().detach().numpy(), axis =1)\n",
        "    prediction_c[batch] = output\n",
        "\n",
        "prediction_c = torch.Tensor(prediction_c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8-Aj-INiPjfJ",
        "colab_type": "code",
        "outputId": "bfc7b9f7-c7c7-4bec-9ee0-f61608778ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "# reshape prediction_a and dicard the last elements corresponding to the padding\n",
        "prediction_c = prediction_c.view(-1)[:-11]\n",
        "print(prediction_c.shape)\n",
        "\n",
        "# Getting back the np.array, and round the result to have 0 or 1\n",
        "prediction_c = prediction_c.numpy()\n",
        "prediction_c = prediction_c.astype(int)\n",
        "print(prediction_c)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([213])\n",
            "[0 0 1 1 1 1 1 2 1 1 2 2 2 0 0 1 2 2 2 0 0 2 1 1 1 1 2 2 0 1 2 1 1 1 2 2 1\n",
            " 1 1 2 1 1 2 2 2 1 2 0 2 2 0 2 0 2 1 1 2 1 1 2 1 1 2 1 1 1 1 0 2 1 1 2 2 0\n",
            " 1 1 1 1 2 2 1 2 1 1 0 1 2 1 1 1 1 2 1 2 0 2 2 1 2 2 0 1 2 1 1 1 0 1 0 2 1\n",
            " 2 1 2 1 1 1 1 1 2 1 0 0 2 1 1 2 1 0 2 1 1 2 1 2 2 1 1 0 0 0 1 1 2 2 1 0 2\n",
            " 0 1 2 1 1 1 0 1 2 2 1 2 2 1 2 1 0 2 1 2 2 1 1 1 1 1 1 1 0 1 1 0 1 1 1 2 1\n",
            " 0 1 2 2 1 1 0 0 1 2 0 1 2 1 2 1 1 1 1 1 1 0 0 1 1 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iUeVkbZxP1WF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "prediction_c_letters = [\"IND\" if element == 1 else \"GRP\" if element == 2 \n",
        "                        else \"OTH\" for element in prediction_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aCAvrvbSQnL8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataframe_c = pd.read_csv('test_set_taskc.tsv', sep=\"\\t\", header=0)\n",
        "id_c = dataframe_c[\"id\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZ-kq0C5Q-0i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred_dataframe = pd.DataFrame(prediction_c_letters, index=id_c)\n",
        "pred_dataframe.to_csv(path_or_buf =\"pred_c.csv\", header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fkpJurVX7L2I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Predictions for task C can now be found in \"Files\"."
      ]
    }
  ]
}